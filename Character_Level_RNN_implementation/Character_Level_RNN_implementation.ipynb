{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "T7tLMuck6Bne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import os\n"
      ],
      "metadata": {
        "id": "OKzTPB4C6Bjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess a text dataset of multiple files"
      ],
      "metadata": {
        "id": "CbsR_EU7opRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data_dir = 'path_to_your_data'  # replace with the path to your data\n",
        "text = ''\n",
        "for filename in os.listdir(data_dir):\n",
        "    with open(os.path.join(data_dir, filename), 'r') as f:\n",
        "        text += f.read()"
      ],
      "metadata": {
        "id": "XG4VY8Bi6BfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_index = dict((c, i) for i, c in enumerate(chars))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "gdmptpzG6BZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode the characters as integers and one-hot vectors"
      ],
      "metadata": {
        "id": "A-TF422CozZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(text) - seq_length, 1):\n",
        "    seq_in = text[i:i + seq_length]\n",
        "    seq_out = text[i + seq_length]\n",
        "    dataX.append([char_to_index[char] for char in seq_in])\n",
        "    dataY.append(char_to_index[seq_out])\n",
        "n_patterns = len(dataX)"
      ],
      "metadata": {
        "id": "Aj226_RR6BS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(len(chars))\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "metadata": {
        "id": "2SyCcAEb6BK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and compile a GRU model with a softmax output layer"
      ],
      "metadata": {
        "id": "4wN65V8go9If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    GRU(256, input_shape=(X.shape[1], X.shape[2])),\n",
        "    Dense(y.shape[1], activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "MhScVsfG6BCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model on the input-output pairs of character sequences"
      ],
      "metadata": {
        "id": "4_8XFSzWo6H8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2msCpxdN57BK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compile and fit the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.fit(X, y, epochs=20, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to sample a character from a probability distribution"
      ],
      "metadata": {
        "id": "VlgM-nZspnP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "\n",
        "preds = np.asarray(preds).astype(‘float64’)\n",
        "\n",
        "preds = np.log(preds) / temperature\n",
        "\n",
        "exp_preds = np.exp(preds)\n",
        "\n",
        "preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "probas = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "return np.argmax(probas)"
      ],
      "metadata": {
        "id": "kLix5Mj8ptiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate new text\n"
      ],
      "metadata": {
        "id": "WWCwG0pdp0To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a random seed\n",
        "start_index = np.random.randint(0, len(text) - seq_length - 1)\n",
        "\n",
        "seed = text[start_index: start_index + seq_length]"
      ],
      "metadata": {
        "id": "PcPs9hs8pxeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate characters"
      ],
      "metadata": {
        "id": "H7q2VUolp-BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generated = ‘’\n",
        "\n",
        "for i in range(200): # generate 200 characters\n",
        "\n",
        "#Encode the seed as one-hot vectors\n",
        "x = np.zeros((1, seq_length, len(chars)))\n",
        "\n",
        "for t, char in enumerate(seed):\n",
        "\n",
        "x[0, t, char_to_index[char]] = 1.\n",
        "\n",
        "#Predict the next character\n",
        "preds = model.predict(x, verbose=0)[0]\n",
        "\n",
        "next_index = sample(preds, temperature=0.5) # adjust the temperature for more or less diversity\n",
        "\n",
        "next_char = index_to_char[next_index]\n",
        "\n"
      ],
      "metadata": {
        "id": "VkElBh90p6ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Append the next character to the generated text and the seed"
      ],
      "metadata": {
        "id": "QpPj9_1KqEIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generated += next_char\n",
        "\n",
        "seed += next_char\n",
        "\n",
        "seed = seed[1:]\n",
        "\n",
        "# Print the generated text\n",
        "print(generated)"
      ],
      "metadata": {
        "id": "DPnCO35mqDej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d9-0V6f4qDHv"
      }
    }
  ]
}